{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43cd0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67bc25b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\projects\\\\generative-models\\\\examples\\\\torch_autoencoder'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89f49cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\projects\\generative-models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'F:\\\\projects\\\\generative-models'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ../..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8b37257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gempy.torch.encoder import ConvEncoder\n",
    "from gempy.torch.decoder import ConvDecoder\n",
    "from gempy.torch.auto_encoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33dfd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (1, 28, 28)\n",
    "z_dim = (4, )\n",
    "z_labels = ('z', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a595281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    print (f'GPU available')\n",
    "    device = 'cuda'\n",
    "\n",
    "x_random = torch.randn(1, *input_dim)\n",
    "x_random = x_random.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d16f088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvEncoder(\n",
       "  (conv_0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (conv_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (latent_flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (latent_z): Linear(in_features=576, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = ConvEncoder(\n",
    "    input_dim=input_dim,\n",
    "    filters=(32, 64, 64, 64),\n",
    "    #filters=(8, 16, 16, 16),\n",
    "    kernel_size=(3, 3, 3, 3),\n",
    "    strides=(1, 2, 2, 1),\n",
    "    activation='leaky_relu',\n",
    "    latent_dim=z_dim,\n",
    "    latent_labels=z_labels,\n",
    "    latent_activation='sigmoid',\n",
    ")\n",
    "\n",
    "encoer = encoder.to(device)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "136095e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvDecoder(\n",
       "  (decode_latent_0): Linear(in_features=4, out_features=576, bias=True)\n",
       "  (decode_conv_t_0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (decode_conv_t_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "  (decode_conv_t_2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "  (decode_conv_t_3): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = ConvDecoder(\n",
    "    latent_dim=z_dim,\n",
    "    latent_upscale=(64, 3, 3),\n",
    "    filters=[64, 64, 32, 1],\n",
    "    #filters=[16, 16, 8, 1],\n",
    "    kernel_size=[3, 4, 4, 3],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    activation=['leaky_relu', 'leaky_relu', 'leaky_relu', 'sigmoid'],\n",
    "    latent_merge=False,\n",
    "    latent_activation=None,\n",
    ")\n",
    "\n",
    "decoder = decoder.to('cuda')\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c37430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer activation:  <function leaky_relu at 0x000001AB67959040>\n",
      "layer activation:  <function leaky_relu at 0x000001AB67959040>\n",
      "layer activation:  <function leaky_relu at 0x000001AB67959040>\n",
      "layer activation:  <built-in method sigmoid of type object at 0x00007FFBDF946620>\n"
     ]
    }
   ],
   "source": [
    "for l in decoder.conv_stack:\n",
    "    print('layer activation: ', l[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93979f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): ConvEncoder(\n",
       "    (conv_0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (conv_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (latent_flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (latent_z): Linear(in_features=576, out_features=4, bias=True)\n",
       "  )\n",
       "  (decoder): ConvDecoder(\n",
       "    (decode_latent_0): Linear(in_features=4, out_features=576, bias=True)\n",
       "    (decode_conv_t_0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (decode_conv_t_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (decode_conv_t_2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (decode_conv_t_3): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_encoder = AutoEncoder(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    ")\n",
    "\n",
    "auto_encoder = auto_encoder.to(device)\n",
    "auto_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79148b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape     : (1, 28, 28)\n",
      "latent shape     : (64, 3, 3)\n",
      "z shape          : (4,)\n",
      "output shape    : (1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print('input shape     :', auto_encoder.encoder.conv_stack_shape_in)\n",
    "print('latent shape     :', auto_encoder.encoder.conv_stack_shape_out)\n",
    "print('z shape          :', z_dim)\n",
    "print('output shape    :', auto_encoder.decoder.conv_stack_shape_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a86bcab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent space    : {'z': tensor([[0.5024, 0.5061, 0.4998, 0.5098]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)}\n",
      "output shape    : torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "y = auto_encoder(x_random)\n",
    "\n",
    "print('latent space    :', encoder.latent_torch)\n",
    "print('output shape    :', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c57f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([4, 576])\n",
      "torch.Size([4])\n",
      "torch.Size([576, 4])\n",
      "torch.Size([576])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 4, 4])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 32, 4, 4])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 1, 3, 3])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for p in auto_encoder.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "453bc077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_cifar10(batch_size, dataset_directory, dataloader_workers):\n",
    "    # Prepare dataset for training\n",
    "    train_transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root=dataset_directory, train=True,\n",
    "                                                 download=True, transform=train_transformation)\n",
    "    \n",
    "    test_dataset =  torchvision.datasets.CIFAR10(root=dataset_directory, train=False,\n",
    "                                                 download=True, transform=train_transformation)\n",
    "\n",
    "    # Prepare Data Loaders for training and validation\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               pin_memory=True, num_workers=dataloader_workers)\n",
    "\n",
    "    return train_dataset, train_loader\n",
    "\n",
    "def get_MNIST(batch_size, dataset_directory, dataloader_workers):\n",
    "    # Prepare dataset for training\n",
    "    train_transformation = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),])\n",
    "    \n",
    "    train_dataset = torchvision.datasets.MNIST(root=dataset_directory, train=True,\n",
    "                                               download=True, transform=train_transformation)\n",
    "    \n",
    "    test_dataset =  torchvision.datasets.MNIST(root=dataset_directory, train=False,\n",
    "                                               download=True, transform=train_transformation)\n",
    "\n",
    "    # Prepare Data Loaders for training and validation\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               pin_memory=True, num_workers=dataloader_workers)\n",
    "\n",
    "    return train_dataset, train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "286c50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_loader = get_MNIST(64, 'examples/torch_autoencoder/data/MNIST', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41c2d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = torch.optim.Adam(auto_encoder.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f51b3148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean-squared error loss\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb58df55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ab68f38d00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_dataset[10][0].detach().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e078b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/100, loss = 0.082558\n",
      "epoch : 2/100, loss = 0.067470\n",
      "epoch : 3/100, loss = 0.067370\n",
      "epoch : 4/100, loss = 0.067330\n",
      "epoch : 5/100, loss = 0.067324\n",
      "epoch : 6/100, loss = 0.067320\n",
      "epoch : 7/100, loss = 0.067306\n",
      "epoch : 8/100, loss = 0.067309\n",
      "epoch : 9/100, loss = 0.067307\n",
      "epoch : 10/100, loss = 0.067307\n",
      "epoch : 11/100, loss = 0.067304\n",
      "epoch : 12/100, loss = 0.067300\n",
      "epoch : 13/100, loss = 0.067308\n",
      "epoch : 14/100, loss = 0.067294\n",
      "epoch : 15/100, loss = 0.067297\n",
      "epoch : 16/100, loss = 0.067293\n",
      "epoch : 17/100, loss = 0.067288\n",
      "epoch : 18/100, loss = 0.067291\n",
      "epoch : 19/100, loss = 0.067288\n",
      "epoch : 20/100, loss = 0.067287\n",
      "epoch : 21/100, loss = 0.067285\n",
      "epoch : 22/100, loss = 0.067287\n",
      "epoch : 23/100, loss = 0.067285\n",
      "epoch : 24/100, loss = 0.067287\n",
      "epoch : 25/100, loss = 0.067287\n",
      "epoch : 26/100, loss = 0.067284\n",
      "epoch : 27/100, loss = 0.067286\n",
      "epoch : 28/100, loss = 0.067283\n",
      "epoch : 29/100, loss = 0.067280\n",
      "epoch : 30/100, loss = 0.067286\n",
      "epoch : 31/100, loss = 0.067281\n",
      "epoch : 32/100, loss = 0.067280\n",
      "epoch : 33/100, loss = 0.067279\n",
      "epoch : 34/100, loss = 0.067278\n",
      "epoch : 35/100, loss = 0.067280\n",
      "epoch : 36/100, loss = 0.067281\n",
      "epoch : 37/100, loss = 0.067283\n",
      "epoch : 38/100, loss = 0.067278\n",
      "epoch : 39/100, loss = 0.067281\n",
      "epoch : 40/100, loss = 0.067279\n",
      "epoch : 41/100, loss = 0.067280\n",
      "epoch : 42/100, loss = 0.067274\n",
      "epoch : 43/100, loss = 0.067276\n",
      "epoch : 44/100, loss = 0.067277\n",
      "epoch : 45/100, loss = 0.067283\n",
      "epoch : 46/100, loss = 0.067278\n",
      "epoch : 47/100, loss = 0.067272\n",
      "epoch : 48/100, loss = 0.067276\n",
      "epoch : 49/100, loss = 0.067274\n",
      "epoch : 50/100, loss = 0.067280\n",
      "epoch : 51/100, loss = 0.067272\n",
      "epoch : 52/100, loss = 0.067276\n",
      "epoch : 53/100, loss = 0.067280\n",
      "epoch : 54/100, loss = 0.067272\n",
      "epoch : 55/100, loss = 0.067273\n",
      "epoch : 56/100, loss = 0.067273\n",
      "epoch : 57/100, loss = 0.067274\n",
      "epoch : 58/100, loss = 0.067272\n",
      "epoch : 59/100, loss = 0.067272\n",
      "epoch : 60/100, loss = 0.067274\n",
      "epoch : 61/100, loss = 0.067272\n",
      "epoch : 62/100, loss = 0.067273\n",
      "epoch : 63/100, loss = 0.067274\n",
      "epoch : 64/100, loss = 0.067270\n",
      "epoch : 65/100, loss = 0.067275\n",
      "epoch : 66/100, loss = 0.067270\n",
      "epoch : 67/100, loss = 0.067270\n",
      "epoch : 68/100, loss = 0.067271\n",
      "epoch : 69/100, loss = 0.067273\n",
      "epoch : 70/100, loss = 0.067271\n",
      "epoch : 71/100, loss = 0.067270\n",
      "epoch : 72/100, loss = 0.067273\n",
      "epoch : 73/100, loss = 0.067274\n",
      "epoch : 74/100, loss = 0.067268\n",
      "epoch : 75/100, loss = 0.067271\n",
      "epoch : 76/100, loss = 0.067272\n",
      "epoch : 77/100, loss = 0.067269\n",
      "epoch : 78/100, loss = 0.067267\n",
      "epoch : 79/100, loss = 0.067270\n",
      "epoch : 80/100, loss = 0.067271\n",
      "epoch : 81/100, loss = 0.067271\n",
      "epoch : 82/100, loss = 0.067272\n",
      "epoch : 83/100, loss = 0.067268\n",
      "epoch : 84/100, loss = 0.067271\n",
      "epoch : 85/100, loss = 0.067265\n",
      "epoch : 86/100, loss = 0.067270\n",
      "epoch : 87/100, loss = 0.067267\n",
      "epoch : 88/100, loss = 0.067266\n",
      "epoch : 89/100, loss = 0.067265\n",
      "epoch : 90/100, loss = 0.067269\n",
      "epoch : 91/100, loss = 0.067267\n",
      "epoch : 92/100, loss = 0.067274\n",
      "epoch : 93/100, loss = 0.067268\n",
      "epoch : 94/100, loss = 0.067268\n",
      "epoch : 95/100, loss = 0.067265\n",
      "epoch : 96/100, loss = 0.067272\n",
      "epoch : 97/100, loss = 0.067264\n",
      "epoch : 98/100, loss = 0.067269\n",
      "epoch : 99/100, loss = 0.067267\n",
      "epoch : 100/100, loss = 0.067270\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for batch_features, _ in train_loader:\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "        # batch_features = batch_features.view(-1, 784).to(device)\n",
    "        batch_features = batch_features.to(device)\n",
    "        \n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute reconstructions\n",
    "        outputs = auto_encoder(batch_features)\n",
    "        \n",
    "        # compute training reconstruction loss\n",
    "        train_loss = criterion(outputs, batch_features)\n",
    "        \n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(train_loader)\n",
    "    \n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "994a0ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1abd60f4ac0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "z_rand = np.random.rand(*z_dim)\n",
    "t_rand = torch.from_numpy(z_rand[None, ...]).float().to(device)\n",
    "\n",
    "y_rand = auto_encoder.decoder(t_rand)\n",
    "\n",
    "y = y_rand[0].detach().cpu().numpy()\n",
    "plt.imshow(y.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fc15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
